---
title: "Varia transformation"
---


### Load rasters

```{r}
rasters_path <- list.files("data/SSS-OC-prep", pattern = "*.tif$", full.names = TRUE)
rs_OC <- terra::rast(rasters_path)
```

### Aggregate on temporal window

#### Subset 2020-2022 temporal window

```{r}
timestamps <- data.frame(idx = 1:terra::nlyr(rs_OC), timestamp = terra::time(rs_OC))
temp_window_OC <- dplyr::filter(timestamps, format(timestamp, "%Y") %in% c(2021:2022))
```

#### Filter on the period

```{r}
rs_OC_period <- rs_OC[[temp_window_OC$idx]]
```

#### Crop for the area of interest and compute number of NA

```{r}
inter_area <- sf::st_read("data/interpolation_area.shp")
rs_OC_period_crop <- terra::crop(rs_OC_period, inter_area, mask = TRUE)
desc_rs <- data.frame(time = terra::time(rs_OC_period_crop), isNA = terra::global(rs_OC_period, fun = "isNA"))
```

#### Get TB descriptors 

```{r}
rasters_path <- list.files("data/SSS-TB-prep", pattern = "*.tif$", full.names = TRUE)
rs_TB <- terra::rast(rasters_path)
```

Filter for the same time-window

```{r}
timestamps <- data.frame(idx = 1:terra::nlyr(rs_TB), timestamp = terra::time(rs_TB))
temp_window_TB <- dplyr::filter(timestamps, format(timestamp, "%Y") %in% c(2021:2022))
rs_TB <- rs_TB[[temp_window_TB$idx]]
```

#### Create datasets

```{r}
df_TB <- as.data.frame(rs_TB, xy = TRUE)
df_OC <- as.data.frame(rs_OC, xy = TRUE)
```

### Extra: Which year as the most IS observations?

Which year has the most salinity in situ observations and what the temporal window for that year?

```{R}

library(feather)
files <- list.files("data/Feather", pattern = "*.feather", full.names = TRUE)

IS_data <- files |>
    purrr::map_df(\(x) {
        feather::read_feather(x) |> dplyr::filter(!is.na(IS))
    }, .progress = TRUE) |>
    dplyr::bind_rows()
    
IS_data |> 
    dplyr::filter(!is.na(OC) & !is.na(TB)) |>
    dplyr::group_by(lubridate::year(date)) |> 
    dplyr::summarize(min = min(date), max = max(date), n = dplyr::n()) |>
    dplyr::arrange(desc(n))
```


## Avec package RandomForest

## Model 1

$$
SSS-OC \sim X + Y + SSS-TB
$$

## Steps 

1. Remove NA values to prepare the training dataset
2. Split 70% traning set and 30% validation
3. Train randomForest
4. Compute p2 and RMSE

```{r}
library(feather)
files <- list.files("data/Feather", pattern = "*.feather", full.names = TRUE)
files <- data.frame(files, timestamp = as.Date(stringr::str_extract(files, "[0-9]{4}-[0-9]{2}-[0-9]{2}")))
```

Filter on time period

```{r}
files_period <- dplyr::filter(files, timestamp >= as.Date("2022-01-01") & timestamp <= as.Date("2022-12-30"))

data <- files_period$files |>
    purrr::map_df(\(x) {
        feather::read_feather(x) |> dplyr::filter(!is.na(TB) & !is.na(OC))
    }, .progress = TRUE) |>
    dplyr::bind_rows()
```

Get in situ points spatial cover

```{R}
data_IS_locations <- dplyr::filter(data, !is.na(IS)) |> 
    sf::st_as_sf(coords = c("lon", "lat"), crs = 4326)

mapview::mapview(data_IS_locations)
```


### Add relative position from the solstice

Get relative time relative position based on winter solstice

```{R}
data$rel_solstice <- TDIML::solstice(as.POSIXct(data$date))
```


## Split example - Training vs validation set

Split data for trainig and validation set with 70% used for training and 30% used for validation

```{r}
set.seed(123)
train_index <- caret::createDataPartition(y = data$OC, p = 0.7, list = FALSE)

data$use_train <- FALSE
data$use_train[train_index] <- TRUE

training_set <- data[train_index, ]
testing_set <- data[-train_index, ]
```

## Calibration

Run the random forest with IS 

```{R}
dplyr::filter(data, !is.na(IS))
```

```{r}
forest <- randomForest::randomForest(
    # Formula.
    y = training_set[,"OC"],
    x = training_set[,c("lat", "lon", "TB")],
    data = training_set,
    method = "rf",
    ntree = 5, 
    importance = TRUE
)

saveRDS(forest, "models/rf_5tree_2022.rds")
forest <- readRDS("models/rf_5tree_2022.rds")
```

## Prediction 

```{R}
testing_set$OC_rf5tree_mod1_pred <- predict(forest, newdata = testing_set)
saveRDS(testing_set, "data/testing_set_rf_2022.rds")
```

## Validation

```{R}
library(ggplot2)
ggplot(data=testing_set, aes(x=IS, y=OC_predicted)) +
  geom_point (col="Black") +
  scale_x_continuous(limits = c(0,35)) +
  scale_y_continuous(limits = c(0,35)) +
  geom_abline() +
  labs(x="Observed", y="Predicted") 

rmse <- function(a, b) {  sqrt(mean((a - b)^2)) }
Psquare <- function(x, y) 1 - sum((x - y)^2)/sum((x - mean(x))^2)

rmse(testing_set$OC, testing_set$OC_rf5tree_mod1_pred)
Psquare(testing_set$OC, testing_set$OC_rf5tree_mod1_pred)
```
