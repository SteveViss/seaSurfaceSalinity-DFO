---
title: "Perform Random forest for interpolation"
---

## Dependancies 

```{r}
# devtools::install_local("path/to/TIDML/package")
# Load equinox and solistice reference dates from TIDML package 
tref <- system.file(
    "extdata",
    "tref.rds",
    package = "TDIML"
) |> readRDS()

```

## Set target folder and sampling parameters

```{r}
nGroup <- 50
nSampleByGroup <- 5
target_dir <- glue::glue("data/randomForest/{nGroup}bins_{nSampleByGroup}samples")
```

## Create list of feather files with timestamp

```{r}
files <- list.files("data/Feather", pattern = "*.feather", full.names = TRUE)
files <- data.frame(
    path = files,
    timestamp = as.Date(stringr::str_extract(files, "[0-9]{4}-[0-9]{2}-[0-9]{2}"))
)
```

## Sample training data

```{r}
cli::cli_alert_info("Preparing training set...")

### Prepare cluster
future::plan(future::multicore, workers = 10)

# Fix seed for reproducible example 
set.seed(123)

# Sample data for randomForest training
training_data <- files |>
    dplyr::pull(path) |>
    furrr::future_map_dfr(\(x) {
        d <- feather::read_feather(x) |>
            dplyr::filter(!is.na(OC) & !is.na(TB))
        tryCatch({
            d |>
                # Generate bins along OC distribution
                dplyr::mutate(sampling_group = as.numeric(ggplot2::cut_number(OC, nGroup))) |>
                dplyr::group_by(sampling_group) |>
                # Uniform random sampling within the bin
                dplyr::slice_sample(n = nSampleByGroup) |>
                dplyr::ungroup() |>
                dplyr::select(-sampling_group)
            }, error = function(e) {
                return(d)
            })
        }, .progress = TRUE, .options = furrr::furrr_options(seed = 123)) 
```

### And solstice and equinox sine variables on training set

```{r}
cli::cli_alert_info("Compute solstice and equinox sins on training set...")

sins <- training_data$date |>
    as.POSIXct() |>
    TDIML::atime(tref)

training_data <- training_data |>
    dplyr::mutate(
        year = lubridate::year(date),
        solSin = sins[,1L],
        equiSin = sins[,2L]
    ) |>
    dplyr::select(-date, -is_origin, -IS)

saveRDS(training_data, glue::glue("{target_dir}/training_data.rds"))
```

### Lookup on OC and TB pixels coverage

```{r}
cli::cli_alert_info("Assert TB and OC pixels coverage from the training set...")

training_set_locations <- training_data |>
    dplyr::group_by(lon, lat) |>
    dplyr::summarise(countOC = sum(!is.na(OC)), countTB = sum(!is.na(TB))) |>
    dplyr::mutate(countOC = dplyr::na_if(countOC, 0), countTB = dplyr::na_if(countTB, 0))

countOC <- terra::rast(
    dplyr::select(training_set_locations, lon, lat, countOC),
    type = "xyz",
    crs = terra::crs("epsg:4326")
)

countTB <- terra::rast(
    dplyr::select(training_set_locations, lon, lat, countTB),
    type = "xyz",
    crs = terra::crs("epsg:4326")
)

mapview::mapview(countOC)
mapview::mapview(countTB)
```

## Random forest

#### Hyperparameters tunning 

https://bradleyboehmke.github.io/HOML/random-forest.html
https://statmath.wu.ac.at/~hornik/DTM/Presentations/pres_ranger.pdf

```{r}
# training_data <- readRDS(glue::glue("{target_dir}/training_data.rds"))
n_features <- length(setdiff(names(training_data), "OC"))

hyper_grid <- expand.grid(
    formula = c(
        "OC ~ lon + lat + year + solSin + equiSin",
        "OC ~ lon + lat + year + solSin + equiSin + TB"
    ),
    mtry = 1:n_features,
    min.node.size = c(1, 3, 5, 10),
    replace = FALSE,
    sample.fraction = c(.5, .63, .8),
    rmse = NA
) |>
    dplyr::mutate(
        modelOCTB = stringr::str_detect(formula, "TB")
    ) |>
    dplyr::filter(!(!modelOCTB & mtry == 6)) # This combinaison is not possible as the number of mtry is superior to the number of independant variables


# execute full cartesian grid search
for (i in cli::cli_progress_along(seq_len(nrow(hyper_grid)), "Hyperparameters tuning")) {
    form <- eval(parse(text = as.character(hyper_grid$formula[i])))
    # fit model for ith hyperparameter combination
    fit <- ranger::ranger(
        formula = form,
        data = dplyr::select(training_data, all.vars(form)),
        num.trees = n_features * 10,
        mtry = hyper_grid$mtry[i],
        min.node.size = hyper_grid$min.node.size[i],
        replace = hyper_grid$replace[i],
        sample.fraction = hyper_grid$sample.fraction[i],
        verbose = FALSE,
        seed = 123,
        respect.unordered.factors = "order",
    )

    # export OOB error
    hyper_grid$rmse[i] <- sqrt(fit$prediction.error)
}

saveRDS(hyper_grid, glue::glue("{target_dir}/hypergrids.rds"))
```

Ranger function subsample the training set to compute the prediction error (RMSE). We then use the RMSE value to find the most accurate set of hyperparameters for the model.

#### Compute the importance of each variable for each selected models (OC and OCTB).

```{r}
cli::cli_alert_info("Compute variable importance for each selected models (OC and OCTB)")

# Load pre-computed data.frames
training_data <- readRDS(glue::glue("{target_dir}/training_data_daily.rds"))
hyper_grid <- readRDS(glue::glue("{target_dir}/hypergrids.rds")) |>
    dplyr::arrange(rmse)

# Isolate selected model with minimal RMSE
selected_model <- list(
    OCTB = dplyr::filter(hyper_grid, modelOCTB) |>
        dplyr::slice_min(n = 1, order_by = rmse) |>
        dplyr::mutate(formula = as.character(formula)) |>
        as.list(),
    OC = dplyr::filter(hyper_grid, !modelOCTB) |>
        dplyr::slice_min(n = 1, order_by = rmse) |>
        dplyr::mutate(formula = as.character(formula)) |>
        as.list()
)

# Compute impurity and permutation model importance
vars_importance <- purrr::map(selected_model, \(model){
    compute_mod <- c("impurity", "permutation")
    outputs <- purrr::map(compute_mod, \(imp){
        form <- eval(parse(text = as.character(model$formula)))
        mod <- ranger::ranger(
            formula = form,
            data = dplyr::select(training_data, all.vars(form)),
            num.trees = 100,
            mtry = model$mtry,
            min.node.size = model$min.node.size,
            replace = model$replace,
            sample.fraction = model$sample.fraction,
            respect.unordered.factors = "order",
            importance = imp,
            verbose = FALSE,
            seed = 123
        )
    }) |> setNames(compute_mod)
    return(outputs)
})

# Save result
saveRDS(vars_importance, glue::glue("{target_dir}/vars_importance.rds"))

library(ggplot2)
figs <- list()
figs$OCTB_impurity <- vip::vip(vars_importance$OCTB$impurity, num_features = vars_importance$OCTB$impurity$num.independent.variables, bar = FALSE) +
    ggtitle("OCTB - Impurity")
figs$OCTB_permutation <- vip::vip(vars_importance$OCTB$permutation, num_features = vars_importance$OCTB$permutation$num.independent.variables, bar = FALSE) +
    ggtitle("OCTB - Permutation")
figs$OC_impurity <- vip::vip(vars_importance$OC$impurity, num_features = vars_importance$OC$impurity$num.independent.variables, bar = FALSE) +
    ggtitle("OC - Impurity")
figs$OC_permutation <- vip::vip(vars_importance$OC$permutation, num_features = vars_importance$OC$permutation$num.independent.variables, bar = FALSE) +
    ggtitle("OC - Permutation")

imp <- gridExtra::grid.arrange(grobs = figs, nrow = 2)
ggsave(file = glue::glue("{target_dir}/figs/importances.png"), imp, width = 10, height = 6)
```

Quick note on variable importance

> The basic idea of the permutation variable importance approach [18] is to consider a variable important if it has a positive effect on the prediction performance. To evaluate this, a tree is grown in the first step, and the prediction accuracy in the OOB observations is calculated. In the second step, any association between the variable of interest x_i and the outcome is broken by permuting the values of all individuals for x_i, and the prediction accuracy is computed again. The difference between the two accuracy values is the permutation importance for x_i from a single tree. The average of all tree importance values in a random forest then gives the random forest permutation importance of this variable. The procedure is repeated for all variables of interest. The package ranger [24] was used in our analyses.

From: https://github.com/imbs-hl/ranger/issues/237
See: https://academic.oup.com/bioinformatics/article/34/21/3711/4994791


### Model validation

#### Compute RMSE with insitu data

```{r}
# Release laptop memory 
rm(list=setdiff(ls(), c("files", "tref", "target_dir")))

# Prepare cluster
future::plan(future::multicore, workers = 10)

# Get pixels 
insitu_set <- files |>
    dplyr::pull(path) |>
    furrr::future_map_dfr(\(x) {
        feather::read_feather(x) |>
            dplyr::filter(!is.na(IS) & !is.na(TB))
    }, .progress = TRUE)

# Isolate
sins <- insitu_set$date |>
    as.POSIXct() |>
    TDIML::atime(tref)

insitu_set <- insitu_set |>
    dplyr::mutate(
        year = lubridate::year(date),
        solSin = sins[, 1L],
        equiSin = sins[, 2L]
    )
```

#### Compute RMSE with satelite derivated OC


Cross validation

```{R}
library(ranger)

# Load selected model
# TBOC vs OC
selected_models <- readRDS(glue::glue("{target_dir}/vars_importance.rds"))
rf_OCTB_selected <- selected_models$OCTB$permutation
rf_OC_selected <- selected_models$OC$permutation

insitu_set$OC_pred_rf_OCTB <- predict(rf_OCTB_selected, insitu_set)$predictions
insitu_set$OC_pred_rf_OC <- predict(rf_OC_selected, insitu_set)$predictions

rmse <- function(a, b) {  sqrt(mean((a - b)^2)) }
Psquare <- function(x, y) 1 - sum((x - y)^2)/sum((x - mean(x))^2)

insitu_set_without_na <- insitu_set |> dplyr::filter(!is.na(OC))

rmse_sat_OCTB <- rmse(insitu_set_without_na$OC, insitu_set_without_na$OC_pred_rf_OCTB)
psquared_sat_OCTB <- Psquare(insitu_set_without_na$OC, insitu_set_without_na$OC_pred_rf_OCTB)
rmse_IS_OCTB <- rmse(insitu_set$IS, insitu_set$OC_pred_rf_OCTB)
psquared_IS_OCTB <- Psquare(insitu_set$IS, insitu_set$OC_pred_rf_OCTB)

rmse_OC <- rmse(insitu_set_without_na$OC, insitu_set_without_na$OC_pred_rf_OC)
psquared_OC <- Psquare(insitu_set_without_na$OC, insitu_set_without_na$OC_pred_rf_OC)
rmse_vs_IS_OC <- rmse(insitu_set$IS, insitu_set$OC_pred_rf_OC)
psquared_vs_IS_OC <- Psquare(insitu_set$IS, insitu_set$OC_pred_rf_OC)

library(ggplot2)

insitu_vs_predOC <- ggplot(data=insitu_set, aes(x=IS, y=OC_pred_rf_OC)) +
    geom_point(col="Black", alpha = 0.3) +
    scale_x_continuous(limits = c(0,35)) +
    scale_y_continuous(limits = c(0,35)) +
    geom_abline(color = "grey50") +
    annotate("text", x = 4, y = 30, label = glue::glue("P ^ 2 == {round(psquared_vs_IS_OC,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 28, label = glue::glue("rmse == {round(rmse_vs_IS_OC,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 26, label = glue::glue("n == {nrow(insitu_set_without_na)}"), parse = TRUE) +
    theme_bw() +
    labs(x="In situ salinity  (g kg^(-1))", y="Predicted salinity (g kg^(-1))") +
    ggtitle("OC - Cross validation against in situ salinity")

sat_vs_predOC <- ggplot(data=insitu_set, aes(x=OC, y=OC_pred_rf_OC)) +
    geom_point(col="Black", alpha = 0.3) +
    scale_x_continuous(limits = c(0,35)) +
    scale_y_continuous(limits = c(0,35)) +
    geom_abline(color = "grey50") +
    annotate("text", x = 4, y = 30, label = glue::glue("P ^ 2 == {round(psquared_OC,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 28, label = glue::glue("rmse == {round(rmse_OC,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 26, label = glue::glue("n == {nrow(insitu_set_without_na)}"), parse = TRUE) +
    theme_bw() +
    labs(x="Satelite derivated salinity (g kg^(-1))", y="Predicted salinity (g kg^(-1))") + 
    ggtitle("OC - Cross validation against satelite derivated salinity")

insitu_vs_predOCTB <- ggplot(data=insitu_set, aes(x=IS, y=OC_pred_rf_OCTB)) +
    geom_point(col="Black", alpha = 0.3) +
    scale_x_continuous(limits = c(0,35)) +
    scale_y_continuous(limits = c(0,35)) +
    geom_abline(color = "grey50") +
    annotate("text", x = 4, y = 30, label = glue::glue("P ^ 2 == {round(psquared_IS_OCTB,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 28, label = glue::glue("rmse == {round(rmse_IS_OCTB,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 26, label = glue::glue("n == {nrow(insitu_set_without_na)}"), parse = TRUE) +
    theme_bw() +
    labs(x="In situ salinity (g kg^(-1))", y="Predicted salinity (g kg^(-1))") +
    ggtitle("OCTB - Cross validation against in situ salinity")

sat_vs_predOCTB <- ggplot(data=insitu_set, aes(x=OC, y=OC_pred_rf_OCTB)) +
    geom_point(col="Black", alpha = 0.3) +
    scale_x_continuous(limits = c(0,35)) +
    scale_y_continuous(limits = c(0,35)) +
    geom_abline(color = "grey50") +
    annotate("text", x = 4, y = 30, label = glue::glue("P ^ 2 == {round(psquared_sat_OCTB,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 28, label = glue::glue("rmse == {round(rmse_sat_OCTB,3)}"), parse = TRUE) +
    annotate("text", x = 4, y = 26, label = glue::glue("n == {nrow(insitu_set_without_na)}"), parse = TRUE) +
    theme_bw() +
    labs(x="Satelite derivated salinity (g kg^(-1))", y="Predicted salinity (g kg^(-1))") + 
    ggtitle("OCTB - Cross validation against satelite derivated salinity")

cross <- gridExtra::grid.arrange(insitu_vs_predOC, insitu_vs_predOCTB, sat_vs_predOC, sat_vs_predOCTB, nrow = 2)
ggsave(file=glue::glue("{target_dir}/figs/cross_validation_rf.png"), cross, width = 12, height = 8)
```

### Notes

There are four main practical disadvantages of RF:

- Depending on data and assumptions about data, it can over-fit values without an analyst even noticing it.
- It predicts well only within the feature space with enough training data. Extrapolation i.e. prediction outside the training space can lead to poor performance (Meyer & Pebesma, 2021).
- It can be computationally expensive with computational load increasing exponentially with the number of covariates.
- It requires quality training data and is highly sensitive to blunders and typos in the data.

Source - https://opengeohub.github.io/spatial-prediction-eml/introduction-to-spatial-and-spatiotemporal-data.html
