---
title: "Perform Random forest for interpolation"
---

## Random forest

#### Load training set

```{r}
nGroup <- 50
nSampleByGroup <- 5
target_dir <- glue::glue("data/randomForest/{nGroup}bins_{nSampleByGroup}samples")

training_data <- readRDS(glue::glue("{target_dir}/training_data.rds"))
```

#### Hyperparameters tunning 

This R code defines and executes a hyperparameter tuning process for a machine learning model using Random Forests (with the ranger package) and stores the results. The code generates a grid of hyperparameter combinations, fits models for each combination, evaluates their performance, and saves the results.

https://bradleyboehmke.github.io/HOML/random-forest.html
https://statmath.wu.ac.at/~hornik/DTM/Presentations/pres_ranger.pdf

```{r}
hyper_grid <- expand.grid(
    formula = c(
        "OC ~ lon + lat + year + solSin + equiSin",
        "OC ~ lon + lat + year + solSin + equiSin + TB",
        "OC ~ lon + lat + year + solSin + equiSin + TB_1pixels_1days",
        "OC ~ lon + lat + year + solSin + equiSin + TB_3pixels_3days",
        "OC ~ lon + lat + year + solSin + equiSin + TB_5pixels_5days"
    ),
    mtry = 1:6, # Number of independant variables used in the model
    min.node.size = c(1, 3, 5, 10),
    replace = FALSE,
    sample.fraction = c(.5, .63, .8),
    rmse = NA
) |>
    dplyr::mutate(
        modelOCTB = stringr::str_detect(formula, "TB")
    ) |>
    dplyr::filter(!(!modelOCTB & mtry == 6)) # This combinaison is not possible as the number of mtry is superior to the number of independant variables

# execute full cartesian grid search
for (i in cli::cli_progress_along(seq_len(nrow(hyper_grid)), "Hyperparameters tuning")) {
    form <- eval(parse(text = as.character(hyper_grid$formula[i])))
    # fit model for ith hyperparameter combination
    fit <- ranger::ranger(
        formula = form,
        data = dplyr::select(training_data, all.vars(form)),
        num.trees = n_features * 10,
        mtry = hyper_grid$mtry[i],
        min.node.size = hyper_grid$min.node.size[i],
        replace = hyper_grid$replace[i],
        sample.fraction = hyper_grid$sample.fraction[i],
        verbose = FALSE,
        seed = 123,
        respect.unordered.factors = "order",
    )

    # export OOB error
    hyper_grid$rmse[i] <- sqrt(fit$prediction.error)
}


saveRDS(hyper_grid, glue::glue("{target_dir}/hypergrids.rds"))
```


#### Compute the importance of each variable for each selected models (OC and OCTB).

```{r}
# Load hypergrid
hyper_grid <- readRDS(glue::glue("{target_dir}/hypergrids.rds")) |>
    dplyr::arrange(rmse)

# Isolate selected model with minimal RMSE
selected_model <- list(
    OCTB = dplyr::filter(hyper_grid, modelOCTB) |>
        dplyr::slice_min(n = 1, order_by = rmse, with_ties = FALSE) |>
        dplyr::mutate(formula = as.character(formula)) |>
        as.list(),
    OC = dplyr::filter(hyper_grid, !modelOCTB) |>
        dplyr::slice_min(n = 1, order_by = rmse, with_ties = FALSE) |>
        dplyr::mutate(formula = as.character(formula)) |>
        as.list()
)

# Compute impurity and permutation model importance
vars_importance <- purrr::map(selected_model, \(model){
    compute_mod <- c("impurity", "permutation")
    outputs <- purrr::map(compute_mod, \(imp){
        form <- eval(parse(text = as.character(model$formula)))
        mod <- ranger::ranger(
            formula = form,
            data = dplyr::select(training_data, all.vars(form)),
            num.trees = 100,
            mtry = model$mtry,
            min.node.size = model$min.node.size,
            replace = model$replace,
            sample.fraction = model$sample.fraction,
            respect.unordered.factors = "order",
            importance = imp,
            verbose = FALSE,
            seed = 123
        )
    }) |> setNames(compute_mod)
    return(outputs)
})

# Save result
saveRDS(vars_importance, glue::glue("{target_dir}/vars_importance.rds"))

library(ggplot2)

figs <- list()

figs$OCTB_impurity <- vip::vip(vars_importance$OCTB$impurity, num_features = vars_importance$OCTB$impurity$num.independent.variables, bar = FALSE) +
    ggtitle("OCTB - Impurity")

figs$OCTB_permutation <- vip::vip(vars_importance$OCTB$permutation, num_features = vars_importance$OCTB$permutation$num.independent.variables, bar = FALSE) +
    ggtitle("OCTB - Permutation")

figs$OC_impurity <- vip::vip(vars_importance$OC$impurity, num_features = vars_importance$OC$impurity$num.independent.variables, bar = FALSE) +
    ggtitle("OC - Impurity")

figs$OC_permutation <- vip::vip(vars_importance$OC$permutation, num_features = vars_importance$OC$permutation$num.independent.variables, bar = FALSE) +
    ggtitle("OC - Permutation")

imp <- gridExtra::grid.arrange(grobs = figs, nrow = 2)
ggsave(file = glue::glue("{target_dir}/figs/importances.png"), imp, width = 10, height = 6)
```

Explanation on importance metrics:

- Impurity-based importance is useful when you need a quick, rough estimate of feature importance, especially during the model training process. However, you should be cautious of potential biases.

- Permutation-based importance is more reliable if you need to understand the true predictive power of each feature and its effect on model performance, especially for deployment or interpretation purposes. However, it's more computationally expensive.

From: https://github.com/imbs-hl/ranger/issues/237
See: https://academic.oup.com/bioinformatics/article/34/21/3711/4994791

